from fastapi import APIRouter, HTTPException
from pydantic import BaseModel
from typing import List, Optional, Dict
import numpy as np
from scipy.linalg import eigh
from scipy.optimize import minimize
import time
from typing import Any
import logging
from concurrent.futures import ProcessPoolExecutor
import multiprocessing

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

router = APIRouter()

# ===== ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹è¨ˆæ¸¬ =====

class PerformanceTimer:
    """ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹è¨ˆæ¸¬ç”¨ã®ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆãƒãƒãƒ¼ã‚¸ãƒ£"""
    def __init__(self, name: str, timing_dict: dict = None):
        self.name = name
        self.timing_dict = timing_dict
        self.start_time = None
        
    def __enter__(self):
        self.start_time = time.perf_counter()
        logger.info(f"â±ï¸  [{self.name}] é–‹å§‹")
        return self
    
    def __exit__(self, *args):
        elapsed = time.perf_counter() - self.start_time
        logger.info(f"âœ… [{self.name}] å®Œäº†: {elapsed:.4f}ç§’")
        if self.timing_dict is not None:
            self.timing_dict[self.name] = round(elapsed, 4)

# ===== Pydanticãƒ¢ãƒ‡ãƒ« =====

class NetworkComparisonRequest(BaseModel):
    networks: List[dict]
    iterations: int = 1
    method: str = "circular_mds"
    n_init: int = 50
    compare_methods: bool = True
    n_workers: Optional[int] = None  # è¿½åŠ ï¼šä¸¦åˆ—ãƒ¯ãƒ¼ã‚«ãƒ¼æ•°ï¼ˆNoneã§è‡ªå‹•ï¼‰

class NetworkComparisonResponse(BaseModel):
    success: bool
    wl_iterations: int
    label_count: int
    kernel_matrix: List[List[float]]
    distance_matrix: List[List[float]]
    coordinates: List[List[float]]
    thetas: List[float]
    circular_coordinates: List[List[float]]
    stress: float
    circular_stress: float
    comparison: Optional[dict] = None
    timing: Optional[Dict[str, float]] = None

# ===== ä¸¦åˆ—åŒ–ç”¨ã®ãƒ˜ãƒ«ãƒ‘ãƒ¼é–¢æ•°ï¼ˆãƒˆãƒƒãƒ—ãƒ¬ãƒ™ãƒ«é–¢æ•°ã¨ã—ã¦å®šç¾©ï¼‰ =====

def _optimize_single_trial(args):
    """å˜ä¸€ã®æœ€é©åŒ–è©¦è¡Œï¼ˆä¸¦åˆ—å®Ÿè¡Œç”¨ï¼‰
    
    Args:
        args: (D_normalized, n, seed) ã®ã‚¿ãƒ—ãƒ«
    
    Returns:
        (stress, thetas) ã®ã‚¿ãƒ—ãƒ«
    """
    D_normalized, n, seed = args
    
    # å„ãƒ¯ãƒ¼ã‚«ãƒ¼ã§ä¹±æ•°ã‚·ãƒ¼ãƒ‰ã‚’è¨­å®š
    np.random.seed(seed)
    
    def circular_distance(theta_i: float, theta_j: float) -> float:
        diff = abs(theta_i - theta_j)
        return min(diff, 2*np.pi - diff)
    
    def stress_function(thetas):
        total = 0
        for i in range(n):
            for j in range(i+1, n):
                circ_dist = circular_distance(thetas[i], thetas[j])
                total += (D_normalized[i,j] - circ_dist)**2
        return total
    
    # ãƒ©ãƒ³ãƒ€ãƒ åˆæœŸåŒ–
    theta0 = np.random.uniform(0, 2*np.pi, n)
    
    # æœ€é©åŒ–
    result = minimize(
        stress_function,
        theta0,
        method='L-BFGS-B',
        bounds=[(0, 2*np.pi)]*n,
        options={'maxiter': 1000}
    )
    
    return (result.fun, result.x)

# ===== å†…éƒ¨è¨ˆç®—é–¢æ•° =====

def classical_mds(distance_matrix: List[List[float]], n_components: int = 2) -> dict:
    """Classical MDS implementation"""
    D = np.array(distance_matrix)
    n = D.shape[0]
    
    if D.shape[0] != D.shape[1]:
        raise ValueError("Distance matrix must be square")
    
    # Double centering
    D_squared = D ** 2
    row_mean = D_squared.mean(axis=1)
    col_mean = D_squared.mean(axis=0)
    total_mean = D_squared.mean()
    
    B = np.zeros((n, n))
    for i in range(n):
        for j in range(n):
            B[i, j] = -0.5 * (D_squared[i, j] - row_mean[i] - col_mean[j] + total_mean)
    
    # Eigenvalue decomposition
    eigenvalues, eigenvectors = eigh(B)
    
    # Sort by eigenvalue (descending)
    idx = np.argsort(eigenvalues)[::-1]
    eigenvalues = eigenvalues[idx]
    eigenvectors = eigenvectors[:, idx]
    
    # Compute coordinates
    coordinates = np.zeros((n, n_components))
    for i in range(n_components):
        if eigenvalues[i] > 0:
            coordinates[:, i] = eigenvectors[:, i] * np.sqrt(eigenvalues[i])
    
    # Normalize to [-1, 1] range
    max_coord = np.max(np.abs(coordinates))
    if max_coord > 0:
        coordinates = coordinates / max_coord
    
    # Calculate stress
    stress = 0
    dist_sum = 0
    for i in range(n):
        for j in range(i + 1, n):
            dx = coordinates[i, 0] - coordinates[j, 0]
            dy = coordinates[i, 1] - coordinates[j, 1]
            embedded_dist = np.sqrt(dx*dx + dy*dy)
            orig_dist = D[i, j]
            stress += (orig_dist - embedded_dist) ** 2
            dist_sum += orig_dist ** 2
    
    stress = np.sqrt(stress / dist_sum) if dist_sum > 0 else 0
    
    return {
        'coordinates': coordinates.tolist(),
        'eigenvalues': eigenvalues[:n_components].tolist(),
        'stress': float(stress)
    }

def circular_mds_parallel(distance_matrix: np.ndarray, n_init: int = 50, n_workers: int = None) -> tuple:
    """è·é›¢è¡Œåˆ—ã‹ã‚‰ç›´æ¥å††ç’°åº§æ¨™ã‚’è¨ˆç®—ï¼ˆä¸¦åˆ—ç‰ˆCircular MDSï¼‰
    
    Args:
        distance_matrix: è·é›¢è¡Œåˆ—
        n_init: åˆæœŸå€¤è©¦è¡Œå›æ•°
        n_workers: ä¸¦åˆ—ãƒ¯ãƒ¼ã‚«ãƒ¼æ•°ï¼ˆNoneã§è‡ªå‹•ï¼šCPUæ•°ï¼‰
    
    Returns:
        (thetas, normalized_stress) ã®ã‚¿ãƒ—ãƒ«
    """
    D = np.array(distance_matrix)
    n = len(D)
    
    # è·é›¢ã‚’[0, Ï€]ã®ç¯„å›²ã«æ­£è¦åŒ–
    max_dist = np.max(D)
    if max_dist > 0:
        D_normalized = (D / max_dist) * np.pi
    else:
        D_normalized = D
    
    # ãƒ¯ãƒ¼ã‚«ãƒ¼æ•°ã®æ±ºå®š
    if n_workers is None:
        n_workers = min(multiprocessing.cpu_count(), n_init)
    
    logger.info(f"   ä¸¦åˆ—Circular MDS: {n_init}å›ã®è©¦è¡Œã‚’{n_workers}ãƒ¯ãƒ¼ã‚«ãƒ¼ã§å®Ÿè¡Œ")
    
    # ä¸¦åˆ—å®Ÿè¡Œã®æº–å‚™ï¼ˆå„è©¦è¡Œã«ç•°ãªã‚‹ã‚·ãƒ¼ãƒ‰ã‚’å‰²ã‚Šå½“ã¦ï¼‰
    args_list = [(D_normalized, n, seed) for seed in range(n_init)]
    
    optimization_start = time.perf_counter()
    
    # ä¸¦åˆ—å®Ÿè¡Œ
    with ProcessPoolExecutor(max_workers=n_workers) as executor:
        results = list(executor.map(_optimize_single_trial, args_list))
    
    optimization_time = time.perf_counter() - optimization_start
    
    # æœ€è‰¯ã®çµæœã‚’é¸æŠ
    best_stress, best_thetas = min(results, key=lambda x: x[0])
    
    # ã‚¹ãƒˆãƒ¬ã‚¹ã‚’æ­£è¦åŒ–
    normalized_stress = np.sqrt(best_stress / (n * (n-1) / 2))
    
    logger.info(f"   ä¸¦åˆ—æœ€é©åŒ–å®Œäº†: {optimization_time:.4f}ç§’")
    logger.info(f"   å®ŸåŠ¹é€Ÿåº¦: {n_init/optimization_time:.1f}è©¦è¡Œ/ç§’ (ç†è«–å€¤: {n_workers}ä¸¦åˆ—)")
    
    return best_thetas, normalized_stress

def circular_mds_sequential(distance_matrix: np.ndarray, n_init: int = 50) -> tuple:
    """è·é›¢è¡Œåˆ—ã‹ã‚‰ç›´æ¥å††ç’°åº§æ¨™ã‚’è¨ˆç®—ï¼ˆé€æ¬¡ç‰ˆCircular MDSï¼‰"""
    
    def circular_distance(theta_i: float, theta_j: float) -> float:
        diff = abs(theta_i - theta_j)
        return min(diff, 2*np.pi - diff)
    
    D = np.array(distance_matrix)
    n = len(D)
    
    # è·é›¢ã‚’[0, Ï€]ã®ç¯„å›²ã«æ­£è¦åŒ–
    max_dist = np.max(D)
    if max_dist > 0:
        D_normalized = (D / max_dist) * np.pi
    else:
        D_normalized = D
    
    def stress_function(thetas):
        total = 0
        for i in range(n):
            for j in range(i+1, n):
                circ_dist = circular_distance(thetas[i], thetas[j])
                total += (D_normalized[i,j] - circ_dist)**2
        return total
    
    # è¤‡æ•°ã®åˆæœŸå€¤ã§æœ€é©åŒ–
    best_result = None
    best_stress = float('inf')
    
    logger.info(f"  ğŸ”„ é€æ¬¡Circular MDS: {n_init}å›ã®è©¦è¡Œ")
    
    for trial in range(n_init):
        theta0 = np.random.uniform(0, 2*np.pi, n)
        
        result = minimize(
            stress_function,
            theta0,
            method='L-BFGS-B',
            bounds=[(0, 2*np.pi)]*n,
            options={'maxiter': 1000}
        )
        
        if result.fun < best_stress:
            best_stress = result.fun
            best_result = result
    
    # ã‚¹ãƒˆãƒ¬ã‚¹ã‚’æ­£è¦åŒ–
    normalized_stress = np.sqrt(best_stress / (n * (n-1) / 2))
    
    return best_result.x, normalized_stress

def compute_circular_stress(D: np.ndarray, thetas: np.ndarray) -> float:
    """å††ç’°è·é›¢ã§ã®ã‚¹ãƒˆãƒ¬ã‚¹è¨ˆç®—"""
    
    def circular_distance(theta_i: float, theta_j: float) -> float:
        diff = abs(theta_i - theta_j)
        return min(diff, 2*np.pi - diff)
    
    n = len(thetas)
    max_dist = np.max(D)
    if max_dist > 0:
        D_normalized = (D / max_dist) * np.pi
    else:
        D_normalized = D
    
    stress = 0
    for i in range(n):
        for j in range(i+1, n):
            circ_dist = circular_distance(thetas[i], thetas[j])
            stress += (D_normalized[i,j] - circ_dist)**2
    
    return np.sqrt(stress / (n * (n-1) / 2))

def compute_wl_kernel(networks: List[dict], iterations: int) -> np.ndarray:
    """Weisfeiler-Lehmanã‚«ãƒ¼ãƒãƒ«è¨ˆç®—"""
    n = len(networks)
    kernel = np.zeros((n, n))
    
    # ãƒ©ãƒ™ãƒ«å±¥æ­´ã‚’ä¿å­˜
    label_histories = []
    
    # åˆæœŸãƒ©ãƒ™ãƒ«ã®è¨­å®š
    for net in networks:
        initial_labels = []
        for node in net['nodes']:
            in_degree = sum(1 for e in net['edges'] if e['target_id'] == node['id'])
            out_degree = sum(1 for e in net['edges'] if e['source_id'] == node['id'])
            degree = in_degree + out_degree
            
            label = f"L{node['layer']}-{node['type'][0].upper()}-D{degree}"
            initial_labels.append(label)
        
        label_histories.append([initial_labels])
    
    # WLåå¾©
    for iter_num in range(iterations + 1):
        if iter_num > 0:
            for net_idx, net in enumerate(networks):
                prev_labels = label_histories[net_idx][iter_num - 1]
                new_labels = []
                
                for node_idx, node in enumerate(net['nodes']):
                    neighbor_info = []
                    
                    for edge in net['edges']:
                        if edge['source_id'] == node['id']:
                            target_idx = next(i for i, n in enumerate(net['nodes']) if n['id'] == edge['target_id'])
                            # weightãŒNoneã‚„æœªå®šç¾©ã®å ´åˆã¯0ã‚’ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ã¨ã—ã¦ä½¿ç”¨
                            weight = edge.get('weight')
                            if weight is None:
                                weight = 0
                            neighbor_info.append({
                                'label': prev_labels[target_idx],
                                'weight': weight
                            })
                        elif edge['target_id'] == node['id']:
                            source_idx = next(i for i, n in enumerate(net['nodes']) if n['id'] == edge['source_id'])
                            # weightãŒNoneã‚„æœªå®šç¾©ã®å ´åˆã¯0ã‚’ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ã¨ã—ã¦ä½¿ç”¨
                            weight = edge.get('weight')
                            if weight is None:
                                weight = 0
                            neighbor_info.append({
                                'label': prev_labels[source_idx],
                                'weight': weight
                            })

                    sorted_neighbors = sorted([
                        f"{info['label']}@{round(info['weight'] * 100) / 100}"
                        for info in neighbor_info
                    ])
                    new_label = f"{prev_labels[node_idx]}|[{','.join(sorted_neighbors)}]"
                    new_labels.append(new_label)
                
                label_histories[net_idx].append(new_labels)
        
        # ã‚«ãƒ¼ãƒãƒ«å€¤ã®æ›´æ–°
        for i in range(n):
            for j in range(i, n):
                labels_i = label_histories[i][iter_num]
                labels_j = label_histories[j][iter_num]
                
                count_i = {}
                count_j = {}
                
                for label in labels_i:
                    count_i[label] = count_i.get(label, 0) + 1
                for label in labels_j:
                    count_j[label] = count_j.get(label, 0) + 1
                
                dot_product = sum(
                    count_i[label] * count_j.get(label, 0)
                    for label in count_i
                )
                
                kernel[i, j] += dot_product
                if i != j:
                    kernel[j, i] += dot_product
    
    # æ­£è¦åŒ–
    normalized_kernel = np.zeros((n, n))
    for i in range(n):
        for j in range(n):
            if kernel[i, i] > 0 and kernel[j, j] > 0:
                normalized_kernel[i, j] = kernel[i, j] / np.sqrt(kernel[i, i] * kernel[j, j])
    
    return normalized_kernel

def kernel_to_distance(kernel: np.ndarray) -> np.ndarray:
    """ã‚«ãƒ¼ãƒãƒ«è¡Œåˆ—ã‹ã‚‰è·é›¢è¡Œåˆ—ã‚’è¨ˆç®—"""
    n = len(kernel)
    distances = np.zeros((n, n))
    
    for i in range(n):
        for j in range(n):
            dist = np.sqrt(max(0, kernel[i, i] + kernel[j, j] - 2 * kernel[i, j]))
            distances[i, j] = dist
    
    return distances

# ===== APIã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ =====

@router.post("/compute_network_comparison", response_model=NetworkComparisonResponse)
async def compute_network_comparison(request: NetworkComparisonRequest):
    """ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯æ§‹é€ æ¯”è¼ƒã®å…¨è¨ˆç®—ã‚’ä¸€æ‹¬å®Ÿè¡Œ"""
    timing = {}
    total_start = time.perf_counter()
    
    try:
        logger.info(f"\n{'='*60}")
        logger.info(f"ğŸš€ ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯æ¯”è¼ƒè¨ˆç®—é–‹å§‹")
        logger.info(f"  ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯æ•°: {len(request.networks)}")
        logger.info(f"  WLåå¾©å›æ•°: {request.iterations}")
        logger.info(f"  MDSæ‰‹æ³•: {request.method}")
        logger.info(f"  n_init: {request.n_init}")
        logger.info(f"  ä¸¦åˆ—ãƒ¯ãƒ¼ã‚«ãƒ¼æ•°: {request.n_workers or 'auto'}")
        logger.info(f"  æ¯”è¼ƒãƒ¢ãƒ¼ãƒ‰: {request.compare_methods}")
        logger.info(f"{'='*60}\n")
        
        # WLã‚«ãƒ¼ãƒãƒ«è¨ˆç®—
        with PerformanceTimer("WLã‚«ãƒ¼ãƒãƒ«è¨ˆç®—", timing):
            kernel_matrix = compute_wl_kernel(request.networks, request.iterations)
        
        # è·é›¢è¡Œåˆ—è¨ˆç®—
        with PerformanceTimer("è·é›¢è¡Œåˆ—è¨ˆç®—", timing):
            distance_matrix = kernel_to_distance(kernel_matrix)
        
        # ãƒ¦ãƒ‹ãƒ¼ã‚¯ãƒ©ãƒ™ãƒ«æ•°
        with PerformanceTimer("ãƒ©ãƒ™ãƒ«æ•°é›†è¨ˆ", timing):
            label_count = len(set(
                f"L{node['layer']}-{node['type'][0]}"
                for net in request.networks
                for node in net['nodes']
            ))
        
        # MDSè¨ˆç®—ï¼ˆæ¯”è¼ƒï¼‰
        comparison_results = {}
        selected_result = None
        
        methods = ['mds_polar', 'circular_mds'] if request.compare_methods else [request.method]
        
        for method in methods:
            method_start = time.perf_counter()
            logger.info(f"\nğŸ“Š MDSè¨ˆç®—é–‹å§‹: {method}")
            
            if method == 'mds_polar':
                with PerformanceTimer(f"MDSè¨ˆç®— ({method})", timing):
                    mds_result = classical_mds(distance_matrix.tolist(), 2)
                    coords = np.array(mds_result['coordinates'])
                    thetas = np.arctan2(coords[:, 1], coords[:, 0])
                    thetas = (thetas + 2*np.pi) % (2*np.pi)
                
                with PerformanceTimer(f"å††ç’°ã‚¹ãƒˆãƒ¬ã‚¹è¨ˆç®— ({method})", timing):
                    circular_stress = compute_circular_stress(distance_matrix, thetas)
                
                stress = mds_result['stress']
            else:  # circular_mds
                with PerformanceTimer(f"Circular MDSè¨ˆç®— ({method})", timing):
                    # ä¸¦åˆ—ç‰ˆã‚’ä½¿ç”¨
                    thetas, circular_stress = circular_mds_parallel(
                        distance_matrix,
                        request.n_init,
                        request.n_workers
                    )
                    stress = circular_stress
                    coords = np.column_stack([np.cos(thetas), np.sin(thetas)])
            
            method_time = time.perf_counter() - method_start
            logger.info(f"âœ… {method} å®Œäº†: {method_time:.4f}ç§’")
            
            result = {
                'stress': float(stress),
                'circular_stress': float(circular_stress),
                'thetas': thetas.tolist(),
                'coordinates': coords.tolist()
            }
            
            comparison_results[method] = result
            
            if method == request.method:
                selected_result = result
        
        # å††ç’°åº§æ¨™ï¼ˆå¯è¦–åŒ–ç”¨ï¼‰
        with PerformanceTimer("å††ç’°åº§æ¨™å¤‰æ›", timing):
            radius = 250
            circular_coords = [
                [radius * np.cos(theta), radius * np.sin(theta)]
                for theta in selected_result['thetas']
            ]
        
        total_time = time.perf_counter() - total_start
        timing['total'] = round(total_time, 4)
        
        logger.info(f"\n{'='*60}")
        logger.info(f"ğŸ‰ å…¨è¨ˆç®—å®Œäº†: {total_time:.4f}ç§’")
        logger.info(f"{'='*60}\n")
        
        logger.info("â±ï¸  å‡¦ç†æ™‚é–“ã‚µãƒãƒªãƒ¼:")
        for key, value in sorted(timing.items(), key=lambda x: -x[1]):
            percentage = (value / total_time * 100) if total_time > 0 else 0
            logger.info(f"  {key:.<40} {value:.4f}ç§’ ({percentage:>5.1f}%)")
        logger.info("")
        
        return NetworkComparisonResponse(
            success=True,
            wl_iterations=request.iterations,
            label_count=label_count,
            kernel_matrix=kernel_matrix.tolist(),
            distance_matrix=distance_matrix.tolist(),
            coordinates=selected_result['coordinates'],
            thetas=selected_result['thetas'],
            circular_coordinates=circular_coords,
            stress=selected_result['stress'],
            circular_stress=selected_result['circular_stress'],
            comparison=comparison_results if request.compare_methods else None,
            timing=timing
        )
        
    except Exception as e:
        import traceback
        traceback.print_exc()
        raise HTTPException(status_code=400, detail=str(e))